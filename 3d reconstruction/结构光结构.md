

# 3D重建功能总体概括

## 图1， 最终产品样式

<img src="https://i.loli.net/2020/08/28/oNmJkajOHWhcv9r.png" alt="image-20200827221645760" style="zoom:50%;" />

## 图2，结构光三维视觉透视模型

<img src="https://i.loli.net/2020/08/28/MztocNR7HPiDTnk.png" alt="image-20200828094506579" style="zoom:50%;" />

> 正如图像所描写，主要工作是根据三角关系，确定转换矩阵把目标物体p(x,y,z)转换到投影仪以及摄像机的成像平面，这一步是系统标定的工作； 另外一个比较重要的工作是将目标物体的点与摄像机的点和3D世界中的点关联起来的点，这一步涉及到编码技术。

# 3D重建关键技术

* 系统标定
* 编码方式
* 相移方法（Phase Shifting Methods)
* 点云计算
* 材质映射

## I: 系统标定

### 1）相机标定

> 参考论文： **Zhang, Z. (1999). Flexible camera calibration by viewing a plane from unknown orientations. Proceedings of the IEEE International Conference on Computer Vision. https://doi.org/10.1109/iccv.1999.791289**

代码实现参考： https://blog.csdn.net/u011574296/article/details/73823569

**主要思路（采用Opencv实现）**

* 找到棋盘图片的的所有的角点(findChessboardCorners)
* 对棋盘的角点进行绘制(drawChessboardCorners)
* 对粗略计算的角点位置进行亚像素化，取得更高精度(find4QuadCornerSubpix,cornerSubPix)
* 根据角点坐标与实际的角点的坐标进行比对，计算摄像机的内外参数(calibrateCamera)
* 计算相机的畸变参数（initUndistortRectifyMap）

### 2)  投影仪标定

**一种比较高效的方法：**

> 参考论文：Wilm, J., Olesen, O. V., & Larsen, R. (2014). Accurate and simple calibration of DLP projector systems. Emerging Digital Micromirror Device Based Systems and Applications VI. https://doi.org/10.1117/12.2038687

通过采集多帧棋盘图片PSP计算方法来将世界坐标转为投影仪的坐标空间，投影仪的镜头畸变自然而然就好了

代码实现参考：https://blog.csdn.net/qq_28713863/article/details/78367940

### 3)  立体标定

立体标定是计算空间上摄像机和投影仪几何关系的过程，立体标定依赖于查找摄像机和投影仪之间的旋转矩阵R和平移向量T。

R和T都可以通过opencv函数: **cvStereoCalibate**来计算获得

> 参考资料: https://www.cnblogs.com/zhazhiqiang2018/p/9538986.html#_Toc25035
>
> 参考论文：基于 OpenCV 和本质矩阵的双目立体视觉摄像机标定方法.

## II: 编码方式

**系统标定的主要目标是确定结构光传感器系统的结构参数，通过编码可以确定投影图像与编码图案对应点的关系**

> 参考论文： Salvi, J., Pagâ, J., & Batlle, J. (2004). Pattern codication strategies in structured light system. 37, 827–849. https://doi.org/10.1016/j.patcog.2003.10.002

### 1) 分时编码

​	**分时编码是按照时间顺序依次投影多幅图案，每次投影对各像素产生一个码值，从而产生一个与各像素一一对应的码值**

* Binary Codes（二值编码）

  主要分为普通二值码和格雷码。

  普通二值码用m个图案来编码2m个条文，相邻的条纹数以2的倍数增加。

  格雷码相邻码值之间的海明距离至多为1，而普通二值码的海明距离可能出现大于1的情形（**具体没看明白**）

  <img src="https://i.loli.net/2020/08/28/H8CyjxDU4NGBctm.png" alt="image-20200828102756129" style="zoom:50%;" />

* n-ary codes

  根据灰度来编码

  <img src="https://i.loli.net/2020/08/28/Io2FXJqiBjsp5Ue.png" alt="image-20200828103523489" style="zoom:50%;" />

* Gray code + Phase shifting

  > 参考资料：https://zhuanlan.zhihu.com/p/110801836

  <img src="https://i.loli.net/2020/08/28/C8FGcHpENbhnTKU.png" alt=" " style="zoom:50%;" />

  

  ```
      //根据二进制转换成格雷码的法则，可以得到以下的代码：
        static unsigned int DecimaltoGray(unsigned int x)
        {
           return x^(x>>1);
        }
  
       //以上代码实现了unsigned int型数据到格雷码的转换，最高可转换32位自然二进制码，超出32位将溢出。   
        static  int DecimaltoGray( int x)
        {
           return x^(x>>1);
        }
  
        //以上代码实现了 int型数据到格雷码的转换，最高可转换31位自然二进制码，超出31位将溢出。       
  ```

  由于环境光，以及物体表面材质的原因，一幅图像中像素的亮度（灰度值）通常是不均匀的，无法直接利用一张图片呈现的灰度信息对结构光解码，但是我们可以利用结构光系列图片来帮助获取像素点当前是亮条纹还是暗条纹的信息。**一个5位的格雷码编码需要投影5张结构光图片**

  对于同一个位置，**可以近似认为其被亮条纹照射到的亮度总是高于其被暗条纹照射到的亮度**。

  > 参考论文： Xu, Y., & Aliaga, D. G. (2007). Robust pixel classification for 3D modeling with structured light. *Proceedings - Graphics Interface*. https://doi.org/10.1145/1268517.1268556

  **对格雷码进行解码**

  ![](https://i.loli.net/2020/08/28/bJFloyKNMwpv4PL.png)

  

* Hybrid method

### 2) 空间编码

​    **空间编码则只需要投影一副编码图案，利用相邻像素信息来产生码值**

* Non-formal codification

* De Bruijn sequences

  <img src="https://i.loli.net/2020/08/28/F87lutEkDWpxMbC.png" alt="image-20200828104503000 " style="zoom:50%;" />

* M-arrays

  <img src="https://i.loli.net/2020/08/28/tDBPq4kxLjloFzY.png" alt="image-20200828104519055 " style="zoom:50%;" />

### 3) 直接编码

​    **直接编码方法利用投影光线的特性，直接为编码图案的每个像素设置一个码值**

* Grey levels

* Colour

  <img src="https://i.loli.net/2020/08/28/mTxPECX2bzv9cyU.png" alt="image-20200828104534400" style="zoom:50%;" />

## III:  相移方法

此处不再展开

## IV：  点云处理

主要采用PCL软件库进行处理

> 参考资料： https://github.com/PointCloudLibrary/pcl

## V： 纹理映射

主要有三个方法：（详细参考以下三个论文）

* Blending-base methods
* Projection-based methods
* Wraping-based  methods

> 参考论文：
>
> Bernardini, F., Martin, L. M., & Rushmeier, H. (2001). High-quality texture reconstruction from multiple scans. *IEEE Transactions on Visualization and Computer Graphics*. https://doi.org/10.1109/2945.965346
>
> Aganj, E., Monasse, P., & Keriven, R. (2010). Multi-view texturing of imprecise mesh. *Lecture Notes in Computer Science (Including Subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)*. https://doi.org/10.1007/978-3-642-12304-7_44
>
> Lempitsky, V., & Ivanov, D. (2007). Seamless mosaicing of image-based texture maps. *Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition*. https://doi.org/10.1109/CVPR.2007.383078

## VI: 软件最终效果



![ ](https://i.loli.net/2020/08/28/F2bDSCJEwtL1hWX.png)
